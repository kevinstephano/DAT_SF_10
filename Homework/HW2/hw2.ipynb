{
 "metadata": {
  "name": "",
  "signature": "sha256:efff0a5e2200a07871921db44d122235c525c8772346c4005496a84a2e773d5e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Import data from CSV file:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "\n",
      "iris_data                 = []\n",
      "iris_data_classifications = []\n",
      "\n",
      "with open( 'iris.csv', 'r' ) as iris_csv_file:\n",
      "    csv_lines = csv.reader( iris_csv_file, delimiter=',' )\n",
      "    for line in csv_lines :\n",
      "        if line : # check for non-empty line\n",
      "            iris_data_classifications.append( line[-1] )\n",
      "            iris_data.append( [ float(item) for item in line[:-1] ] )\n",
      "        \n",
      "# Show first 10 entries    \n",
      "for x in xrange(0,10) :\n",
      "    print( \"{0} --> {1}\".format( iris_data[x], iris_data_classifications[x] ) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[5.1, 3.5, 1.4, 0.2] --> Iris-setosa\n",
        "[4.9, 3.0, 1.4, 0.2] --> Iris-setosa\n",
        "[4.7, 3.2, 1.3, 0.2] --> Iris-setosa\n",
        "[4.6, 3.1, 1.5, 0.2] --> Iris-setosa\n",
        "[5.0, 3.6, 1.4, 0.2] --> Iris-setosa\n",
        "[5.4, 3.9, 1.7, 0.4] --> Iris-setosa\n",
        "[4.6, 3.4, 1.4, 0.3] --> Iris-setosa\n",
        "[5.0, 3.4, 1.5, 0.2] --> Iris-setosa\n",
        "[4.4, 2.9, 1.4, 0.2] --> Iris-setosa\n",
        "[4.9, 3.1, 1.5, 0.1] --> Iris-setosa\n"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Define Nearest Neighbors and Cross Validation functions:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.cross_validation import KFold\n",
      "import numpy\n",
      "\n",
      "def KNearestNeighbors( neighbors, data, classifications ) :\n",
      "    k_nearest_neighbors = KNeighborsClassifier(n_neighbors=neighbors,weights='uniform')\n",
      "    k_nearest_neighbors.fit(data, classifications)\n",
      "    return k_nearest_neighbors\n",
      "\n",
      "def CrossValidate( data, classifications, classifier_func, neighbors, k_folds ) :\n",
      "    k_fold_indices = KFold( len(data), n_folds=k_folds, shuffle=True, random_state=0)\n",
      "    \n",
      "    data_array            = numpy.array( data )\n",
      "    classifications_array = numpy.array( classifications )\n",
      "\n",
      "    k_score_total = 0\n",
      "    # for each training and testing slices run the classifier, and score the results\n",
      "    for train_slice, test_slice in k_fold_indices :\n",
      "        model = classifier_func( neighbors, data_array[ train_slice  ], classifications_array[ train_slice ] )\n",
      "        k_score = model.score( data_array[ test_slice ], classifications_array[ test_slice ] )\n",
      "        k_score_total += k_score\n",
      "\n",
      "    # return the average accuracy\n",
      "    return k_score_total/k_folds\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Find optimal number of neighbors:\n",
      "(uniform weighting of neighbors)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import operator\n",
      "\n",
      "# Over 120 neighbors fail because the training set only uses 80% of the data set with 5 folds\n",
      "neighbor_scores = {}\n",
      "# Making a map of \"Number of Neighbors\" to \"Cross Validation Score\"\n",
      "for n in xrange(1,121) :\n",
      "    neighbor_scores[n] = CrossValidate( iris_data, iris_data_classifications, KNearestNeighbors, n, 5 )\n",
      "\n",
      "# Sort map in order of best \"Cross Validation Score\" and only show the first 20 scores of 120\n",
      "sorted_neighbor_scores = sorted( neighbor_scores.items(), key=operator.itemgetter(1), reverse=True )\n",
      "for key,val in sorted_neighbor_scores[:20] :\n",
      "    print ( \"Neighbors: {0} Score: {1}\".format( key, val) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Neighbors: 11 Score: 0.966666666667\n",
        "Neighbors: 15 Score: 0.966666666667\n",
        "Neighbors: 1 Score: 0.96\n",
        "Neighbors: 4 Score: 0.96\n",
        "Neighbors: 5 Score: 0.96\n",
        "Neighbors: 8 Score: 0.96\n",
        "Neighbors: 9 Score: 0.96\n",
        "Neighbors: 10 Score: 0.96\n",
        "Neighbors: 12 Score: 0.96\n",
        "Neighbors: 13 Score: 0.96\n",
        "Neighbors: 3 Score: 0.953333333333\n",
        "Neighbors: 6 Score: 0.953333333333\n",
        "Neighbors: 7 Score: 0.953333333333\n",
        "Neighbors: 14 Score: 0.953333333333\n",
        "Neighbors: 22 Score: 0.953333333333\n",
        "Neighbors: 16 Score: 0.946666666667\n",
        "Neighbors: 17 Score: 0.946666666667\n",
        "Neighbors: 19 Score: 0.946666666667\n",
        "Neighbors: 20 Score: 0.946666666667\n",
        "Neighbors: 21 Score: 0.946666666667\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Plot Result \"Accuracy vs K Nearest Neighbors\":"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "(Play entire notebook to see plot.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import pyplot\n",
      "\n",
      "neighbor_scores_x = []\n",
      "neighbor_scores_y = []\n",
      "\n",
      "for key,val in sorted_neighbor_scores:\n",
      "    neighbor_scores_x.append( key )\n",
      "    neighbor_scores_y.append( val )\n",
      "    \n",
      "x_array = numpy.array( neighbor_scores_x )\n",
      "y_array = numpy.array( neighbor_scores_y )\n",
      "\n",
      "plot = pyplot.figure(0)\n",
      "scat = plot.add_subplot(1,1,1)\n",
      "scat.scatter(x_array, y_array)\n",
      "scat.set_xlabel(\"K Nearest Neighbors\", fontsize=8)\n",
      "scat.set_ylabel(\"Accuracy Score\", fontsize=8)\n",
      "pyplot.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Written question:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The graph seems to show that there are steps of accuracy.  For the number of neighbors between 0 to ~65, there is an accuracy greater than ~85%.  Past around ~65 there is a drop off where there is another shelf around 75 to 115 neighbors where the accurcy is around ~50%.  Since there are only 3 categories in the data set and there is roughly 40 data points for each category, I think that at around 80 neighbors you might be getting an equal number of data points in each category to get you 50% accuracy given that each neighbor is uniformally weighted as the default.  When you change the weighting to 'distance', the non-default, you see that 1-120 neighbors are all above 93% accuracy where the optimal choice is 5 neighbors instead of 11 which could be computationally cheaper depending on the complexity of weighting the calculation."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Bonus Section:"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Iterating over 2-15 Folds and 1-N Neighbors to find the optimal score for changing the number of folds."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "11 Folds with 13 neighbors appears to be the most accurate option."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import operator\n",
      "from mpl_toolkits.mplot3d import Axes3D\n",
      "\n",
      "# Over 120 neighbors fail because the training set only uses 80% of the data set with 5 folds\n",
      "neighbor_scores_bonus = {}\n",
      "# Making a map of \"Number of Neighbors\" to \"Cross Validation Score\"\n",
      "for folds in xrange(2,16) :\n",
      "    neighbor_scores_bonus[folds] = {}\n",
      "    range_of_folds = 0\n",
      "    if (150 % folds) != 0:\n",
      "        range_of_folds = (150 - (150 / folds) )\n",
      "    else:\n",
      "        range_of_folds = ( 150 - ( 150 / folds ) ) + 1\n",
      "    for n in xrange(1, range_of_folds ):\n",
      "        #print(\"Folds{0} Neighbors{1}\".format(folds,n))\n",
      "        neighbor_scores_bonus[folds][n] = CrossValidate( iris_data, iris_data_classifications, KNearestNeighbors, n, folds )\n",
      "\n",
      "        \n",
      "fold_and_neighbor_scores = {}\n",
      "for folds in neighbor_scores_bonus:\n",
      "    for neighbors in neighbor_scores_bonus[folds]:\n",
      "        key_str = str(folds) + \"_\" + str(neighbors)\n",
      "        fold_and_neighbor_scores[key_str] = neighbor_scores_bonus[folds][neighbors]\n",
      "        \n",
      "# Sort map in order of best \"Cross Validation Score\" and only show the first 20 scores of 120\n",
      "sorted_fold_and_neighbor_scores = sorted( fold_and_neighbor_scores.items(), key=operator.itemgetter(1), reverse=True )\n",
      "for folds_neighbors,val in sorted_fold_and_neighbor_scores[:50] :\n",
      "    print ( \"Folds_Neighbors: {0} Score: {1}\".format( folds_neighbors, val) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Folds_Neighbors: 11_19 Score: 0.98001998002\n",
        "Folds_Neighbors: 11_13 Score: 0.98001998002\n",
        "Folds_Neighbors: 11_15 Score: 0.973526473526\n",
        "Folds_Neighbors: 11_20 Score: 0.973526473526\n",
        "Folds_Neighbors: 9_13 Score: 0.973447712418\n",
        "Folds_Neighbors: 9_19 Score: 0.973447712418\n",
        "Folds_Neighbors: 6_15 Score: 0.973333333333\n",
        "Folds_Neighbors: 8_15 Score: 0.97331871345\n",
        "Folds_Neighbors: 12_13 Score: 0.973290598291\n",
        "Folds_Neighbors: 9_17 Score: 0.973039215686\n",
        "Folds_Neighbors: 11_18 Score: 0.973026973027\n",
        "Folds_Neighbors: 11_17 Score: 0.973026973027\n",
        "Folds_Neighbors: 11_21 Score: 0.973026973027\n",
        "Folds_Neighbors: 8_19 Score: 0.972953216374\n",
        "Folds_Neighbors: 8_13 Score: 0.972953216374\n",
        "Folds_Neighbors: 14_18 Score: 0.972727272727\n",
        "Folds_Neighbors: 14_19 Score: 0.972727272727\n",
        "Folds_Neighbors: 14_15 Score: 0.972727272727\n",
        "Folds_Neighbors: 14_17 Score: 0.972727272727\n",
        "Folds_Neighbors: 14_23 Score: 0.972727272727\n",
        "Folds_Neighbors: 12_20 Score: 0.967414529915\n",
        "Folds_Neighbors: 12_19 Score: 0.967414529915\n",
        "Folds_Neighbors: 12_14 Score: 0.967414529915\n",
        "Folds_Neighbors: 13_19 Score: 0.967365967366\n",
        "Folds_Neighbors: 11_14 Score: 0.967032967033\n",
        "Folds_Neighbors: 4_11 Score: 0.96692745377\n",
        "Folds_Neighbors: 9_15 Score: 0.966911764706\n",
        "Folds_Neighbors: 9_27 Score: 0.966911764706\n",
        "Folds_Neighbors: 12_21 Score: 0.96688034188\n",
        "Folds_Neighbors: 12_23 Score: 0.96688034188\n",
        "Folds_Neighbors: 12_22 Score: 0.96688034188\n",
        "Folds_Neighbors: 12_12 Score: 0.96688034188\n",
        "Folds_Neighbors: 12_11 Score: 0.96688034188\n",
        "Folds_Neighbors: 12_17 Score: 0.96688034188\n",
        "Folds_Neighbors: 13_17 Score: 0.966783216783\n",
        "Folds_Neighbors: 10_14 Score: 0.966666666667\n",
        "Folds_Neighbors: 15_17 Score: 0.966666666667\n",
        "Folds_Neighbors: 15_15 Score: 0.966666666667\n",
        "Folds_Neighbors: 15_13 Score: 0.966666666667\n",
        "Folds_Neighbors: 15_11 Score: 0.966666666667\n",
        "Folds_Neighbors: 15_19 Score: 0.966666666667\n",
        "Folds_Neighbors: 6_5 Score: 0.966666666667\n",
        "Folds_Neighbors: 3_5 Score: 0.966666666667\n",
        "Folds_Neighbors: 3_6 Score: 0.966666666667\n",
        "Folds_Neighbors: 2_10 Score: 0.966666666667\n",
        "Folds_Neighbors: 6_21 Score: 0.966666666667\n",
        "Folds_Neighbors: 6_20 Score: 0.966666666667\n",
        "Folds_Neighbors: 6_11 Score: 0.966666666667\n",
        "Folds_Neighbors: 6_19 Score: 0.966666666667\n",
        "Folds_Neighbors: 3_11 Score: 0.966666666667\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Ploting the results in a 3D scatter plot of \"Folds vs Neighbors vs Accuracy Score\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mpl_toolkits.mplot3d import Axes3D\n",
      "\n",
      "x = []\n",
      "y = []\n",
      "z = []\n",
      "for folds in neighbor_scores_bonus:\n",
      "    for neighbors in neighbor_scores_bonus[folds]:\n",
      "        x.append( folds )\n",
      "        y.append( neighbors )\n",
      "        z.append( neighbor_scores_bonus[folds][neighbors] )\n",
      "        \n",
      "\n",
      "x_array = numpy.array( x )\n",
      "y_array = numpy.array( y )\n",
      "z_array = numpy.array( z )\n",
      "\n",
      "plot2 = pyplot.figure(0)\n",
      "scat2 = plot2.add_subplot(111, projection='3d')\n",
      "scat2.scatter(x_array, y_array, z_array)\n",
      "scat2.set_xlabel(\"K Folds\", fontsize=8)\n",
      "scat2.set_ylabel(\"K Nearest Neighbors\", fontsize=8)\n",
      "scat2.set_zlabel(\"Accuracy Score\", fontsize=8)\n",
      "pyplot.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "It looks like the large numbers of folds with a smaller test slice are more accurate.\n",
      "This also implies the training set is larger with more folds.  Although, the optimal number\n",
      "of folds is not 15, the largest number tried.\n",
      "\n",
      "11 folds is said to be optimal from the data but I am not sure if a data set of 150 is good\n",
      "enough to make that determination."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}